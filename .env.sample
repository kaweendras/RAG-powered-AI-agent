# Server configuration
PORT=4000

# Vector Database selection (CHROMADB or PINECONE)
VECTORDB_TYPE="CHROMADB"

# ChromaDB configuration
CHROMADB_URL="http://localhost:8000"
CHROMADB_COLLECTION="handbook"

# Pinecone configuration (only needed if VECTORDB_TYPE is PINECONE)
PINECONE_API_KEY="YOUR_PINECONE_API_KEY"
PINECONE_INDEX_NAME="handbook-index"

# Embedding and Model configuration
EMBEDDINGS_MODEL="nomic-embed-text:v1.5"
OLLAMA_MODEL="llama3.2:latest"
OLLAMA_API_URL="http://localhost:11434"

# Google AI (Gemini) configuration
GOOGLEAI_MODEL_NAME=gemini-2.0-flash
GOOGLEAI_API_KEY="YOUR_GOOGLEAI_API_KEY"
GOOGLEAI_API_URL=https://generativelanguage.googleapis.com/v1beta/models/

# Generation parameters
TEMPERATURE=0.2
SEED=42 